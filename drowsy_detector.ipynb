{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0712a95-4f4d-4c06-8b10-3dcd1d0c4192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df69b6a5-6e9b-4bc7-acdb-ad140c6010a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9778119-7574-4a89-abbc-45c45f6454d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def plot_imgs(directory, top=10):\n",
    "    all_item_dirs = os.listdir(directory)\n",
    "    item_files = [os.path.join(directory, file) for file in all_item_dirs][:5]\n",
    "  \n",
    "    plt.figure(figsize=(20, 20))\n",
    "  \n",
    "    for i, img_path in enumerate(item_files):\n",
    "        plt.subplot(10, 10, i+1)\n",
    "    \n",
    "        img = plt.imread(img_path)\n",
    "        plt.tight_layout()         \n",
    "        plt.imshow(img, cmap='gray') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b082d2e-90a1-4e62-b925-d3f0b482dd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_datagen = ImageDataGenerator(horizontal_flip = True, \n",
    "                                  rescale = 1./255, \n",
    "                                  zoom_range = 0.2, \n",
    "                                  validation_split = 0.1)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2ed6a18-b850-4784-94f9-4161e67f32bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3400 images belonging to 2 classes.\n",
      "Found 600 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_path = 'dataset/train'\n",
    "test_data_path = 'dataset/test'\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(train_data_path, target_size = (64,64),\n",
    "                                              batch_size = batch_size, \n",
    "                                              color_mode = 'grayscale',\n",
    "                                              class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(test_data_path, target_size = (64,64),\n",
    "                                              batch_size = batch_size, \n",
    "                                              color_mode = 'grayscale',\n",
    "                                              class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a6e1a6d-84a3-4426-9e06-d384b554c86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 64, 64, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 32, 32, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 16, 16, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 8, 8, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                524352    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 617154 (2.35 MB)\n",
      "Trainable params: 617154 (2.35 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "classes = 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding = 'same', input_shape = (64,64,1), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(128,(3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) \n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(classes, activation = 'softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad0c2207-f2bf-4b75-82a3-c928256adec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',optimizer = 'adam' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bca618c8-f53a-45f5-9693-2aa51696538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"drowsy_detector.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, \n",
    "                              save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95977202-bdd8-44aa-aa84-f2f83b4705f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "training_steps=train_set.n//train_set.batch_size\n",
    "validation_steps =test_set.n//test_set.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3737004-ae05-4886-b0a0-ca4befe671c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_12076\\2180583923.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_set, epochs=num_epochs, steps_per_epoch=training_steps,validation_data=test_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.3521 - accuracy: 0.8275\n",
      "Epoch 1: val_accuracy improved from -inf to 0.97569, saving model to drowsy_detector.h5\n",
      "106/106 [==============================] - 36s 316ms/step - loss: 0.3521 - accuracy: 0.8275 - val_loss: 0.0728 - val_accuracy: 0.9757\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 0.9715\n",
      "Epoch 2: val_accuracy improved from 0.97569 to 0.97917, saving model to drowsy_detector.h5\n",
      "106/106 [==============================] - 32s 298ms/step - loss: 0.0834 - accuracy: 0.9715 - val_loss: 0.0620 - val_accuracy: 0.9792\n",
      "Epoch 3/20\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.9804\n",
      "Epoch 3: val_accuracy improved from 0.97917 to 0.99653, saving model to drowsy_detector.h5\n",
      "106/106 [==============================] - 32s 299ms/step - loss: 0.0616 - accuracy: 0.9804 - val_loss: 0.0125 - val_accuracy: 0.9965\n",
      "Epoch 4/20\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9875\n",
      "Epoch 4: val_accuracy improved from 0.99653 to 1.00000, saving model to drowsy_detector.h5\n",
      "106/106 [==============================] - 31s 296ms/step - loss: 0.0371 - accuracy: 0.9875 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9961\n",
      "Epoch 5: val_accuracy did not improve from 1.00000\n",
      "106/106 [==============================] - 32s 299ms/step - loss: 0.0171 - accuracy: 0.9961 - val_loss: 8.8888e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9905\n",
      "Epoch 6: val_accuracy did not improve from 1.00000\n",
      "106/106 [==============================] - 32s 302ms/step - loss: 0.0266 - accuracy: 0.9905 - val_loss: 3.9341e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9952\n",
      "Epoch 7: val_accuracy did not improve from 1.00000\n",
      "106/106 [==============================] - 32s 298ms/step - loss: 0.0185 - accuracy: 0.9952 - val_loss: 5.5749e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9890\n",
      "Epoch 8: val_accuracy did not improve from 1.00000\n",
      "106/106 [==============================] - 32s 305ms/step - loss: 0.0321 - accuracy: 0.9890 - val_loss: 2.7251e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9944\n",
      "Epoch 9: val_accuracy did not improve from 1.00000\n",
      "106/106 [==============================] - 31s 292ms/step - loss: 0.0157 - accuracy: 0.9944 - val_loss: 6.1913e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9976\n",
      "Epoch 10: val_accuracy did not improve from 1.00000\n",
      "106/106 [==============================] - 34s 316ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 2.6899e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9988\n",
      "Epoch 11: val_accuracy did not improve from 1.00000\n",
      "106/106 [==============================] - 32s 302ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 5.2034e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9970\n",
      "Epoch 12: val_accuracy did not improve from 1.00000\n",
      "106/106 [==============================] - 32s 302ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 6.1353e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9979\n",
      "Epoch 13: val_accuracy did not improve from 1.00000\n",
      "106/106 [==============================] - 32s 298ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 1.5015e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9970\n",
      "Epoch 14: val_accuracy did not improve from 1.00000\n",
      "106/106 [==============================] - 33s 307ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 8.7780e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9961\n",
      "Epoch 15: val_accuracy did not improve from 1.00000\n",
      "106/106 [==============================] - 32s 301ms/step - loss: 0.0146 - accuracy: 0.9961 - val_loss: 3.7166e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 16: val_accuracy did not improve from 1.00000\n",
      "106/106 [==============================] - 33s 307ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 3.1701e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "106/106 [==============================] - ETA: 0s - loss: 6.4164e-04 - accuracy: 1.0000\n",
      "Epoch 17: val_accuracy did not improve from 1.00000\n",
      "106/106 [==============================] - 33s 307ms/step - loss: 6.4164e-04 - accuracy: 1.0000 - val_loss: 1.1207e-06 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "106/106 [==============================] - ETA: 0s - loss: 7.9422e-04 - accuracy: 1.0000\n",
      "Epoch 18: val_accuracy did not improve from 1.00000\n",
      "106/106 [==============================] - 33s 310ms/step - loss: 7.9422e-04 - accuracy: 1.0000 - val_loss: 3.8453e-07 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9994\n",
      "Epoch 19: val_accuracy did not improve from 1.00000\n",
      "106/106 [==============================] - 33s 310ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 1.8284e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9994\n",
      "Epoch 20: val_accuracy did not improve from 1.00000\n",
      "106/106 [==============================] - 33s 308ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 3.0009e-07 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_set, epochs=num_epochs, steps_per_epoch=training_steps,validation_data=test_set,\n",
    "                    validation_steps=validation_steps, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43aa4ce9-e7b1-40d0-b704-00838d6abde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"drowsy.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcb91ef-edcd-483c-8718-46b129c85b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
